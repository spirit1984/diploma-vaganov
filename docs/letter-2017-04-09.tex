\documentclass[11pt,a4paper,oneside]{article}
\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english,russian]{babel}
\usepackage{expdlist}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{euscript}
\usepackage{amsthm}
\usepackage[pdftex,hyperindex,unicode,colorlinks=true]{hyperref}
\usepackage{cmap}
\hypersetup{
  pdftitle           = {Концепция системы},
  pdfauthor          = {Дмитрий Шевченко},
  pdfsubject         = {Ведомость},
  pdfstartview       = {FitH},
  pdfborder          = {0 0 0},
  bookmarksopen      = true,
  bookmarksnumbered  = true,
  bookmarksopenlevel = 2
}

\hoffset=-25mm \voffset=-35mm \textheight=250mm \textwidth=175mm
\sloppy
\begin{document}

\newtheorem{example}{Пример}
\newtheorem{task}{Задача}
\newtheorem{heuristic}{Эвристика}
\title{Концепция системы}
\author{Шевченко Д.В.}

\maketitle

Итак, вкратце, какова задача:

\begin{task}
Имеется текст $T$ а также дан образец $P$. И текст, и образец состоят из символов алфавита $\{T,G,A,C\}$. Необходимо определить расположение образца в тексте с учетом того, что в образец либо текст могли быть внесены вставки, замены и удаления символов. Необходимо определить помимо расположение образца последовательность операций минимального размера, благодаря которой этот образец можно получить из подстроки текста.
\end{task}

\begin{example}
	Пусть $T=aaaabbbb$, а $P=ab$. Тогда образец входит в текст с позиции 4, а минимальная стоимость равна нулю.
\end{example}

\begin{example}
	Пусть $T=aaaabbbb$, а $P=bab$. Тогда образец входит в текст с позиции 4, а минимальная стоимость равна 1 - одному удалению из образца символа $b$ в начале.
\end{example}

В основе идеи того, как это искать, лежит очень простая идея. Пусть $|T|=m$ (т.е. текст состоит из $m$ символов), а $|P|=n$ (обычно при картировании генома $n\ll m$). Определим функцию $f(p,t)$ как минимальную стоимость для получения подстроки образца с первого символа до $p$-го включительно, из любой подстроки текста с 1 по $t$ включительно. Заодно определим $\delta(x,y)$, как функцию стоимости замены одного символа на другой:

\begin{equation}
	\delta(x,y) = \begin{cases}
	1,\ x\neq y\\
	0,\ x = y\\
	\end{cases}
\end{equation}

Эта функция нужна для того, чтобы проще было описать функцию стоимости. Тогда функцию стоимости можно определить так:


\begin{equation}
\label{eq:cost}
	f(p,t) = \begin{cases}
	0,\ p = 0\\
	1+f(p-1,t),\ t = 0\\
	\min(f(p,t-1), 1+f(p-1,t), 1+f(p,t-1), f(p-1,t-1)+\delta(P_p,T_t) )\ otherwise\\
	\end{cases} 
\end{equation}

Разберем детально, что описывает эта функция. Случай первый $f(0,t)$ - это когда образец из 0 символов (т.е. пустую строку) нужно получить из подстроки $T$, очевидно, что стоимость этого равна нулю, поскольку пустая строка является по определению подстрокой любой строки. Второй случай - это когда образец нужно получить из пустой строки, очевидно, это можно сделать только удалением всех символов из образца. Несложно видеть, что это рекурсивное определение в таком случае:

\begin{equation}
	f(p,0) = p
\end{equation}

Далее, последний кейс - когда непустую подстроку образца мы ищем в непустой подстроке текста. Здесь имеются следующие варианты, из которых нужно выбрать один с минимальной стоимостью. Первый кейс - когда мы игнорируем последний символ подстроки $T$ и ищем подстроку образцу в начале подстроки. Второй кейс - когда из подстроки $P$ удаляется один символ. Третий кейс - когда из подстроки $T$ удаляется один символ. Наконец четвертый кейс - когда символ образца заменяется на символ текста - при этом, если они равны, стоимость такой замены равна нулю. Тогда, минимальная стоимость равняется:

\begin{equation}
	\min_{x\in 1\ldots m} f(n,x)
\end{equation}

Сама идея проста, однако есть некоторые проблемы. Базово, размер текста для генома вируса полноценного занимает порядка $2\cdot 10^5$ символов, а образец обычно порядка $10^4$ символов. Очевидно, что если реализовывать это напрямую, то потребуется памяти:

\begin{equation}
	O(n\cdot m) = O(2\cdot 10^5\cdot 10^4) = O(2\cdot 10^9)
\end{equation}

Т.е. около 2 гигабайт оперативной памяти (также очевидно, что в худшем случае потребуется $O(n\cdot m)$ времени). Очевидно, это много. Есть несколько эвристик, которые позволяют это резко уменьшить и будут описаны далее.

\begin{heuristic}
	\textbf{Буферизация}. Согласно предметной области, с которой мы работаем, образец размера $n$ можно искать, разбивая текст $T$ по частям. Поскольку не может быть такой ситуации, когда образец на 10 тысяч символов разбит таким образом, что первые пять тысяч символов находятся в начале текста, а оставшиеся 5 тысяч попали в конец описания вируса. Этого не бывает, следовательно, можно разбивать текст на части по $2\cdot n$ символов, и анализировать их отдельно. Тогда требуется памяти $O(2\cdot n^2)$ и столько же требуется на поиск в этом буфере.
\end{heuristic}

Почему именно $2\cdot n$? Очень просто - это ограничение на размер буфера сверху, поскольку мы ограничены сверху стоимостью $n$ (т.е. просто $n$ удалений из образца дадут пустую подстроку, которая входит в любой текст). Следовательно, механизм такой, сначала проанализировать текст в диапазоне от 1 до $2\cdot n$, затем от $n$ до $3\cdot n$. Обратите внимание, что старт поиска смещается каждый раз на $n$, чтобы не пропустить различные перекрытия образца. С памятью все ясно, получаем значительное уменьшение:

\begin{equation}
	n\ll m\implies 2\cdot n^2\ll n\cdot m
\end{equation}

А что со временем выполнения?

\begin{equation}
    \label{eq:timebuffer}
	O(2\cdot n^2\cdot \frac{m}{n}) = O(2\cdot n\cdot m)
\end{equation}

Таким образом, благодаря буферизации получаем своеобразный компромисс -памяти требуется меньше, но время на поиск в худшем случае увеличивается вдвое. Это приемлемо для биологов, выполняющих картирование генома. Грубо говоря, отправить задачу приложению на анализ и работать 10 минут над другими ежедневными задачами в ожидании ответа - это лучше, чем ждать пять минут, но при этом не иметь возможности делать на компьютере что-либо еще, из-за того, что повышенные траты памяти приводят к резкому торможению систему. Кроме того, буферизация позволяет выполнять анализ отдельных буферов параллельно (в отличии от решения без буферизации), следовательно, на современных многоядерных процессорах такое решение будет работать даже быстрее, чем решение без буфера. Однако это не единственный способ оптимизации.

\begin{heuristic}
\textbf{Двойной проход по тексту}.
Статистика картирования генома говорит, что 80 процентов геномов находятся в гене вируса без искажений - т.е. стоимость операций равна нулю. Значит, можно обойтись затратами по памяти $O(2\cdot m)$.
\end{heuristic}

Так, откуда такая цифра? Обратите внимание на определение функции $f$ в определении \ref{eq:cost}. Для того, чтобы вычислить $f(x,y)$, нам нужно знать $f(x-1,\ast)$ (предыдущий уровень), но не $f(x-2,\ast)$. Т.е. мы можем обойтись матрицей $2\times m$, которая хранит в себе две строки - текущую и предыдущую. Тогда при первом проходе мы используем именно ее и за время $O(n\cdot m)$ вычислим все, что нужно. Если стоимость получилась равной нулю, то второй проход не нужен, т.к. можно однозначно теперь сказать, где образец находится в тексте и как он выглядел до искажений (поскольку их нет, то он выглядел так же). Если же стоимость не равна нулю, то нужно провести еще один проход с буферизацией, который был описан выше. Однако в 80 процентах случаев второй проход не потребуется. Это позволяет снизить затраты с $O(2\cdot n^2)$ до $O(2\cdot m)$. Если учесть, что образец обычно по длине около 10 процентов от длины текста, то это позволяет уменьшить затраты памяти:

\begin{equation}
	O(\frac{2\cdot n^2}{2\cdot 10\cdot n}) = O(\frac{n}{10})
\end{equation}

Т.к. $10\ll n$, то экономия получается существенная. Времени на первый проход требуется порядка $O(n\cdot m)$. Что касается второго прохода, то за счет информации, полученной при первом проходе, можно снизить затраты по памяти и времени следующим образом:

\begin{heuristic}
\textbf{Буферизация с учетом стоимости}. Обычно отдельный белок (т.е. образец) попадает в вирус (т.е. текст) с небольшим количеством искажений, максимум меняется один-два символа и не более того. Тогда можно использовать вместо буфера $O(2\cdot n^2)$ буфер размером $n\cdot (n+k)$, где $k$ - количество искажений. Просматривать же текст можно по позициям от 1 до $(n+k)$, затем от $(n-k)$ до $2\cdot n$, затем от $2\cdot n -k$ до $3\cdot n$ и т.д.
\end{heuristic}

В крайнем случае (когда $k=n$), мы получаем исходный вариант буферизации с буфером двойного размера. Однако для случаев, когда $k\ll n$, мы получаем вместо памяти $O(2\cdot n^2)$ память:

\begin{equation}
	O(n\cdot(n+k))\approx O(n^2)
\end{equation}

Т.е. в два раза меньше. Что касается временных затрат:

\begin{equation}
	O(n\cdot (n+k)\cdot\frac{m}{n+k})\approx O(n\cdot m)
\end{equation}

Что в два раза меньше, чем требовалось согласно \ref{eq:timebuffer}.

\end{document}
